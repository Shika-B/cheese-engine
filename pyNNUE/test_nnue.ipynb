{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25880223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import chess\n",
    "from nnue import HIDDEN_SIZE, INPUT_SIZE, EVAL_SCALE, fen_to_onehot, NNUE\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8853962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77c3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['short fen'] = df['FEN'].map(lambda s : s.split(\" \")[0])\n",
    "#df['score'] = df['Evaluation'].map(lambda x : 0.5 + min(1000, max(-1000, x)) / 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17512d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 256\n",
    "#testing_df = df.sample(frac=0.01)\n",
    "#test_dataset = np.array_split(testing_df[['short fen', 'score']], int(len(testing_df) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7a9cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingNNUE(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.l1 = nn.Linear(INPUT_SIZE, HIDDEN_SIZE, bias=True)\n",
    "        self.l2 = nn.Linear(2 * HIDDEN_SIZE, 1, bias = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)      # (B, H)\n",
    "        x = torch.concat((x, -x), dim=-1)   # (B, 2*H)\n",
    "        x = torch.square(torch.clip(x, 0, 1))\n",
    "        x = self.l2(x)\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044f75b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TrainingNNUE()\n",
    "model.load_state_dict(torch.load(\"./models/nnue1.ckpt\", weights_only  = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `TrainingNNUE([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `TrainingNNUE([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 1 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 20},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.0+cu126',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"x\"<FLOAT,[768]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"sigmoid\"<FLOAT,[1]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"l1.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
       "                %\"l2.bias\"<FLOAT,[1]>{TorchTensor<FLOAT,[1]>(Parameter containing: tensor([-0.0477], requires_grad=True), name='l2.bias')},\n",
       "                %\"val_0\"<FLOAT,[768,256]>{Tensor(...)},\n",
       "                %\"val_6\"<FLOAT,[512,1]>{Tensor(...)},\n",
       "                %\"concat_min\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(0., dtype=float32), name='concat_min')},\n",
       "                %\"concat_max\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1., dtype=float32), name='concat_max')},\n",
       "                %\"val_5\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(2., dtype=float32), name='val_5')}\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # node_MatMul_1\n",
       "                 %\"val_1\"<FLOAT,[256]> ⬅️ ::MatMul(%\"x\", %\"val_0\"{...})\n",
       "            1 |  # node_linear\n",
       "                 %\"linear\"<FLOAT,[256]> ⬅️ ::Add(%\"val_1\", %\"l1.bias\"{...})\n",
       "            2 |  # node_neg\n",
       "                 %\"neg\"<FLOAT,[256]> ⬅️ ::Neg(%\"linear\")\n",
       "            3 |  # node_concat\n",
       "                 %\"concat\"<FLOAT,[512]> ⬅️ ::Concat(%\"linear\", %\"neg\") {axis=-1}\n",
       "            4 |  # node_Clip_8\n",
       "                 %\"clamp\"<FLOAT,[512]> ⬅️ ::Clip(%\"concat\", %\"concat_min\"{0.0}, %\"concat_max\"{1.0})\n",
       "            5 |  # node_pow_1\n",
       "                 %\"pow_1\"<FLOAT,[512]> ⬅️ ::Pow(%\"clamp\", %\"val_5\"{2.0})\n",
       "            6 |  # node_MatMul_7\n",
       "                 %\"val_7\"<FLOAT,[1]> ⬅️ ::MatMul(%\"pow_1\", %\"val_6\"{...})\n",
       "            7 |  # node_linear_1\n",
       "                 %\"linear_1\"<FLOAT,[1]> ⬅️ ::Add(%\"val_7\", %\"l2.bias\"{[-0.04769467934966087]})\n",
       "            8 |  # node_sigmoid\n",
       "                 %\"sigmoid\"<FLOAT,[1]> ⬅️ ::Sigmoid(%\"linear_1\")\n",
       "            return %\"sigmoid\"<FLOAT,[1]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_l1_weight: \"f32[256, 768]\", p_l1_bias: \"f32[256]\", p_l2_weight: \"f32[1, 512]\", p_l2_bias: \"f32[1]\", x: \"f32[768]\"):\n",
       "                     # File: c:\\Users\\monte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[256]\" = torch.ops.aten.linear.default(x, p_l1_weight, p_l1_bias);  x = p_l1_weight = p_l1_bias = None\n",
       "            \n",
       "                     # File: C:\\Users\\monte\\AppData\\Local\\Temp\\ipykernel_13084\\4091201382.py:9 in forward, code: x = torch.concat((x, -x), dim=-1)   # (B, 2*H)\n",
       "                    neg: \"f32[256]\" = torch.ops.aten.neg.default(linear)\n",
       "                    concat: \"f32[512]\" = torch.ops.aten.concat.default([linear, neg], -1);  linear = neg = None\n",
       "            \n",
       "                     # File: C:\\Users\\monte\\AppData\\Local\\Temp\\ipykernel_13084\\4091201382.py:10 in forward, code: x = torch.square(torch.clip(x, 0, 1))\n",
       "                    scalar_tensor_default: \"f32[]\" = torch.ops.aten.scalar_tensor.default(0, dtype = torch.float32)\n",
       "                    scalar_tensor_default_1: \"f32[]\" = torch.ops.aten.scalar_tensor.default(1, dtype = torch.float32)\n",
       "                    clamp: \"f32[512]\" = torch.ops.aten.clamp.Tensor(concat, scalar_tensor_default, scalar_tensor_default_1);  concat = scalar_tensor_default = scalar_tensor_default_1 = None\n",
       "                    pow_1: \"f32[512]\" = torch.ops.aten.pow.Tensor_Scalar(clamp, 2);  clamp = None\n",
       "            \n",
       "                     # File: c:\\Users\\monte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_1: \"f32[1]\" = torch.ops.aten.linear.default(pow_1, p_l2_weight, p_l2_bias);  pow_1 = p_l2_weight = p_l2_bias = None\n",
       "            \n",
       "                     # File: C:\\Users\\monte\\AppData\\Local\\Temp\\ipykernel_13084\\4091201382.py:12 in forward, code: return torch.sigmoid(x)\n",
       "                    sigmoid: \"f32[1]\" = torch.ops.aten.sigmoid.default(linear_1);  linear_1 = None\n",
       "                    return (sigmoid,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_l1_weight: PARAMETER target='l1.weight'\n",
       "            p_l1_bias: PARAMETER target='l1.bias'\n",
       "            p_l2_weight: PARAMETER target='l2.weight'\n",
       "            p_l2_bias: PARAMETER target='l2.bias'\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            sigmoid: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.onnx.export(model,(torch.randn((768,)),) , dynamo = True, f='./models/nnue1.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d196562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38837289810180664\n",
      "0.5725052356719971\n"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "nnue = NNUE()\n",
    "\n",
    "nnue.params['acc_weights'] = model.l1.weight.squeeze().detach().numpy()\n",
    "nnue.params['acc_biases'] = model.l1.bias.squeeze().detach().numpy()\n",
    "nnue.params['output_weights'] = model.l2.weight.squeeze().detach().numpy()\n",
    "nnue.params['output_bias'] = model.l2.bias.squeeze().detach().numpy()\n",
    "\n",
    "board = chess.Board()\n",
    "board.set_board_fen()\n",
    "m1 = fen_to_onehot(board.board_fen())\n",
    "nnue.first_forward(m1)\n",
    "\n",
    "board.push(next(board.generate_legal_moves()))\n",
    "m2 = fen_to_onehot(board.board_fen())\n",
    "\n",
    "s = time.time()\n",
    "for _ in range(1000) : nnue.first_forward(fen_to_onehot(board.board_fen()))\n",
    "print(time.time() - s)\n",
    "\n",
    "s = time.time()\n",
    "for _ in range(1000) : nnue.forward(fen_to_onehot(board.board_fen()))\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf3574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.4146), tensor(3.3894))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "board.set_board_fen(\"7Q/p1p1kppp/4b1q1/8/8/2NP4/PPP2PPP/R1B1R1K1\")\n",
    "board.turn = not board.turn\n",
    "m1 = fen_to_onehot(board.board_fen())\n",
    "m2 = fen_to_onehot(board.mirror().board_fen())\n",
    "nnue.first_forward(m2), nnue.first_forward(m1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
